<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Q.Liu</title>
    <description>Welcome to Q.Liu&#39;s Homepage. Here you can find something about my research interests.</description>
    <link>http://qianchaoliu.github.io//</link>
    <atom:link href="http://qianchaoliu.github.io//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 23 Aug 2016 21:31:38 +0800</pubDate>
    <lastBuildDate>Tue, 23 Aug 2016 21:31:38 +0800</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>NLP with Neural Network</title>
        <description>&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;    本文是使用神经网络的方法进行自然语言处理的技术路线，以Stanford的CS224d课程为主，仅供参考。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;1.一些必要的知识&lt;/h3&gt;
&lt;p&gt;    1.&lt;strong&gt;线性代数&lt;/strong&gt;，包括矩阵的运算，以及模，秩，特征值、特征向量以及和导数求解相关的矩阵知识(比如牛顿法中的Hessian Matrix)等。 &lt;br /&gt;
    2.&lt;strong&gt;概率论&lt;/strong&gt;，包括概率密度函数，条件概率，联合概率，贝叶斯，协方差等。 &lt;br /&gt;
    3.&lt;strong&gt;凸优化&lt;/strong&gt;，包括什么是凸集合，凸函数，如何进行。   &lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.课程正文&lt;/h3&gt;

&lt;h3 id=&quot;section-2&quot;&gt;2.1词向量&lt;/h3&gt;

&lt;p&gt;    本小节的重点是word vectors，介绍了词汇向量化的几种经典的方法。&lt;/p&gt;

&lt;p&gt;    首先介绍了使用descrete representation(比如one-hot)的方法进行词汇向量化的方法，其中一个典型的代表就是使用WordNet这样的&lt;strong&gt;字典&lt;/strong&gt;,但是直接使用字典的方式来将词汇向量化，有很多问题存在： &lt;br /&gt;
1. 会丢失很多词汇的本意细节(nuance), 比如一词多义的问题没办法保留多个意思。&lt;br /&gt;
2. wordnet中的词汇有限，不能及时覆盖所有的词汇。 &lt;br /&gt;
3. 不能直接用来计算词汇之间的相似性。   &lt;/p&gt;

&lt;p&gt;    第二种表示方式是使用neighbors的count来表示词汇，其思想是&lt;strong&gt;一个词可以用句子中它周围的词来表示&lt;/strong&gt;。该种方法有两种的选择，一个是使用“full document”，另一个种是使用“windows”；前者的思想又引出了latent semantic analysis(可以用于文章分类等)；使用neighbors来进行词汇的表达存在的问题包括： &lt;br /&gt;
1. 需要维护高维矩阵，该矩阵需要大量的存储空间 &lt;br /&gt;
2. 模型的鲁棒性不高   &lt;br /&gt;
    由此，针对上述问题，提出的解决方式是进行矩阵降维，常用的方法包括：SVD（对于&lt;script type=&quot;math/tex&quot;&gt;m n&lt;/script&gt;矩阵，时间复杂度为&lt;script type=&quot;math/tex&quot;&gt;o(mn^{2})&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
n&lt; m %]]&gt;&lt;/script&gt;）,此外SVD分解的方法实现词汇向量化对于新词汇的加入不是很友好。      &lt;/p&gt;

&lt;p&gt;    除了第二种方法中的使用临近词汇的count来表示，并通过一定的降维方式来实现word embedding外，还有一种方式是&lt;strong&gt;直接生成低维向量&lt;/strong&gt;(其实这个低维一般也有几百维)。该种方法的思想是通过训练机器学习模型来“modeling”词向量,其代表方法包括Google的word2vec，其特点是对于新的词汇有较好的接收。该种方法通过建立目标函数，使用梯度下降(链式法则)的方法来maximize/minimize目标函数。 &lt;br /&gt;
    其基本步骤包括： &lt;br /&gt;
1. 定义目标函数/Cost &lt;br /&gt;
2. small random numbers初始化参数（对于Word2vec 参数为2&lt;em&gt;V&lt;/em&gt;d个数，其中V为字典长度，d为每个word的词向量维度,这里的2是因为对于每一个词有v,u两个向量来表示,一般使用词向量时，v+u作为结果） &lt;br /&gt;
3. 对Cost进行SGD(Updating parameters with each window in Word2Vec) &lt;br /&gt;
    针对Word2vec这种方法可以展开思考一些问题，比如每个window的词比较少，这样梯度是稀疏的(参数中只有2c+1个参数需要更新，w为window长)，为解决该问题，只处理(更新)目标2c+1个参数(by only update certain columns of full embedding matrix U(left or right words) and V(center word))。      &lt;/p&gt;

&lt;p&gt;    下面给出Word2Vec的目标函数的子项(每一个窗口内的neighbor词&lt;script type=&quot;math/tex&quot;&gt;o&lt;/script&gt;均对应下面给的exponent概率)：  &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$p(o|c)=\frac{exp(v_{c}^{T}u_{o})}{\sum_{w=1}^W exp(v_{c}^{T} u_{w})}$$  &lt;/div&gt;

&lt;p&gt;    In above formula, we could find that we need to sum all the exponent function of neighbor words, which is computationally expensive. Hence, we change the objective function.   &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$J(\theta)=log \sigma(u_{o}^{T}v_{c}) + \sum_{t=1}^k E_{j \~ P(w)}[log \sigma(-u_{j}^{T}v_{c})]$$  &lt;/div&gt;

&lt;p&gt;    改成上式后的方法，叫做Negative Sampling, 其中&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;可以取10，20这样的数；&lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;是sigmoid function。&lt;script type=&quot;math/tex&quot;&gt;\sigma(-x)=1-\sigma(x)&lt;/script&gt;；Rondom函数有特定的设计，corpus中频繁出现的词，更有可能被选出来，但是这个可能性要低于它在corpus中出现的频率。我们认为Negative Sampling相比于之前的目标函数，增加了额外的信息：使不相关的(random)的词汇距离尽可能远。   &lt;/p&gt;

&lt;h3 id=&quot;word-window-classification-and-nerual-network&quot;&gt;2.2 Word window classification and nerual network&lt;/h3&gt;
&lt;p&gt;    分类，在自然语言中的用处包括：从词到词的预测(比如说补全句子)，情感分析，命名实体识别（named entity），分析决策（sell/buy decision），翻译等。下面将给出分类的相关内容。  &lt;br /&gt;
    &lt;strong&gt;LR&lt;/strong&gt;,Logistic Regression(之前blog里介绍过的SVM只会给出分类的结果，而LG会给出分类的概率，比如分为正类的可能性)，LG是使用sigmoid函数，相当于线性回归之后加入了Logistic变换。   &lt;/p&gt;

&lt;p&gt;    NLP的Classification与传统意义上的classification的不同在于，NLP中除了训练模型的参数外，还可以把词向量加入到需要训练的参数中，并且，当训练集非常大时，同时进行词向量的训练(update)，效果较好。 &lt;br /&gt;
然后引入Window classificaition,一般对单个word的分类，在实际场景中很少用到，此外，word在句子中包含的信息会更多，因此，我们对NLP进行分类时，一般是指window classification。   &lt;/p&gt;

&lt;p&gt;    单层神经网络(one hidden layer nn/three layers nn)，对于windows classification问题，比如其中一个sentence窗口是”Museums in Pairs are amazing”，用&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;来表示,且&lt;script type=&quot;math/tex&quot;&gt;x \in \mathbb{R}^{20 \times 1}&lt;/script&gt;，然后根据我们设计的隐层metric（结点的数目），可以假设&lt;script type=&quot;math/tex&quot;&gt;W \in \mathbb{R}^{8 \times 20}&lt;/script&gt;,由隐层到输出层的映射&lt;script type=&quot;math/tex&quot;&gt;U \in \mathbb{R}^{8 \times 1}&lt;/script&gt;,可得&lt;script type=&quot;math/tex&quot;&gt;s = U^{T} \times f(Wx+b) \in \mathbb{R}&lt;/script&gt;,s即为分类的得分(score)。 &lt;br /&gt;
    如果说”Museums in Pairs are amazing”是True window,那么可以定义一些corrupt windows,比如(not all museums in Paris),通过训练，使true windows的得分&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;高，corrupt windows得分&lt;script type=&quot;math/tex&quot;&gt;S_{c}&lt;/script&gt;低。比如可以将目标函数定义为：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$minimize J,  J = max(0,1-S+S_{c})$$  &lt;/div&gt;

&lt;p&gt;    该目标函数叫做Max-Margin Objective function,在实际操作中一般忽略左侧的max和0。对于每一个true window，都需要sample几个corrupt windows。 &lt;br /&gt;
    这里尝试推导&lt;script type=&quot;math/tex&quot;&gt;W_{ij}&lt;/script&gt;的梯度：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$\frac{\Delta S}{\Delta W_{ij}} = U_{i} \frac{\Delta f(Wx+b)}{\Delta W_{ij}} = U_{i} \frac{f^{&#39;}(Wx+b) \Delta(Wx+b)}{\Delta W_{ij}} = U_{i} f^{&#39;}(Wx+b) x_{j} = U_{i}f^{&#39;}(z_{i})x_{j}= \delta _{i}x_{j}$$    &lt;/div&gt;

&lt;p&gt;    当&lt;script type=&quot;math/tex&quot;&gt;f(z)&lt;/script&gt;为sigmoid function时，&lt;script type=&quot;math/tex&quot;&gt;f^{&#39;}(z) = 1 - f(z)&lt;/script&gt;,且有&lt;script type=&quot;math/tex&quot;&gt;z_{i} = w_{i}x+b_{i} = \sum_{j=1}^n W_{ij}x_{j} + b_{i} &lt;/script&gt;,其中&lt;script type=&quot;math/tex&quot;&gt;\delta _{i}&lt;/script&gt;称为local error signal，&lt;script type=&quot;math/tex&quot;&gt;x_{j}&lt;/script&gt;称为local input signal    &lt;/p&gt;

&lt;p&gt;    接下来介绍第一个tip，反向传播计算时的参数复用，&lt;script type=&quot;math/tex&quot;&gt;\frac{\Delta S}{\Delta W_{ij}} = U_{i}f^{&#39;}(z_{i})x_{j}=U_{i}(1-f(z_{i}))x_{j}&lt;/script&gt;,作为activation &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;的error message (responsibility). 这样就可以省去计算了；同理可以求得biases &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;，可知&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;是完全不增加新的计算量的。   &lt;/p&gt;

&lt;p&gt;    第二个tip，Multi-task learning/Weight sharing。其思想是可以通过参数共享来同时训练多个tasks，比如NLP中的词性标注POS(Part-of-Speech) ，NER（Named Entity Recognition）可以同时进行，两个模型在隐层使用同样的weights，但在output层使用不同的weights参数。      &lt;/p&gt;

&lt;p&gt;    接下来介绍了一些训练神经网络的细节：&lt;/p&gt;

&lt;p&gt;    1. 激活函数：1）&lt;script type=&quot;math/tex&quot;&gt;logistic&lt;/script&gt;(sigmoid)，&lt;script type=&quot;math/tex&quot;&gt;f^{&#39;}(z)=f(z)(1-f(z))&lt;/script&gt;； &lt;br /&gt;
                        2）&lt;script type=&quot;math/tex&quot;&gt;tanh&lt;/script&gt;:&lt;script type=&quot;math/tex&quot;&gt;\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}&lt;/script&gt;,并且&lt;script type=&quot;math/tex&quot;&gt;tanh(z)=2logistic(2z)-1&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;f^{&#39;}(z)=1-f(z)^{2}&lt;/script&gt; &lt;br /&gt;
                        3) &lt;script type=&quot;math/tex&quot;&gt;ReLu&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;max(0,x)&lt;/script&gt;   &lt;/p&gt;

&lt;p&gt;    2. Gradient check，作为神经网络中的“debug”，gradient check可以帮助我们确定梯度计算的准确性。梯度的计算是通过pen-and-paper（推导出来的导数式），而check的时候，通过数值近似的方法来计算：&lt;script type=&quot;math/tex&quot;&gt;f^{&#39;}(\theta)=\frac{J(\theta + \epsilon)+J(\theta - \epsilon)}{2\epsilon}&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;非常小，为&lt;script type=&quot;math/tex&quot;&gt;10^{-4}&lt;/script&gt;数量级，然后比较两个计算结果，确定其相差不多。&lt;/p&gt;

&lt;p&gt;    3. Model simplification, start from simplest model to find bugs.&lt;/p&gt;

&lt;p&gt;    4. Parameter Initialization, 假设&lt;script type=&quot;math/tex&quot;&gt;W_{ij} \in [-1,1]&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;x_{j} \in [-100,100]&lt;/script&gt;，并且&lt;script type=&quot;math/tex&quot;&gt;b_{i} \in [-100,100]&lt;/script&gt;，这样，对于&lt;script type=&quot;math/tex&quot;&gt;a_{i}=f(z_{i})=tanh(z_{i})&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;z_{i}&lt;/script&gt;过大，对导致tanh的梯度接近于0，不利于优化。通常情况下我们将&lt;script type=&quot;math/tex&quot;&gt;b_{i}&lt;/script&gt;初始化为0，&lt;script type=&quot;math/tex&quot;&gt;W_{ij}\~uniform(-r,r)&lt;/script&gt;
，并且&lt;script type=&quot;math/tex&quot;&gt;r=\sqrt[]{6/(fan.in + fan.out)}&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;fan.in&lt;/script&gt;是上一层layer，units的个数。注意上式是tanh的参考值，对于sigmoid，应该乘上4.&lt;/p&gt;

&lt;p&gt;    5. SGD, 更新参数的频率,对于大的数据集，SGD优于all batch methods。对于小的数据集,L-BFGS 或者Conjugate Gradients方法更合适。比较常用的是mini-batch SGD, 20到1000大小的batch，这样也有利于并行计算。对于参数的更新，除了最基础的learning-rate &lt;script type=&quot;math/tex&quot;&gt;\times&lt;/script&gt; gradient,还有一些延伸： &lt;br /&gt;
                        1)Momentum,由于SGD的更新完全依赖于当前的batch，这种更新方向可能是十分不稳定的，于是在此处引入momentum，在该次batch的更新中，保留上次更新的影响。&lt;script type=&quot;math/tex&quot;&gt;v=uv-\alpha \delta_{\theta}J_{t}(\theta)&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt;的初始值是0，&lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;为0到1的正数，可取0.9。Momentum的收敛速度更快，而且能够跳出局部最优点。除此之外，还可以改变learning rate &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;：当training validation error不再改变时，&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;减0.5；此外对于频繁出现的word，可以使用较低的learning rate，对于rare的word，使用较高的learning rate。&lt;/p&gt;

&lt;p&gt;    6. Regularize,当遇到样本小，参数多的情况，可能会有过拟合的现象发生，这里引入解决办法：1，最简单的方法是改变Model Size，减少结点的数目，层的数目。2，Standard L1 or L2 regularization on weights。3，early stop,use parameters that gave best validation error。4，Drop out，1）在training time,随机将50units结点的输入设为0；2)在testing time,将所有的weight除以2(修补1带来的部分影响)&lt;/p&gt;

&lt;h3 id=&quot;language-model&quot;&gt;2.3 Language model&lt;/h3&gt;
&lt;p&gt;    A &lt;strong&gt;language model&lt;/strong&gt; computes a probability for a sequence of words：&lt;script type=&quot;math/tex&quot;&gt;P(w_{1},w_{2}...w_{T})&lt;/script&gt;。有了language model,便可以知道哪些word拼凑起来更像一个句子，比如the cat is small比small the cat is更符合我们对于句子的定义，这些特性在machine translation中帮助我们进行翻译。我们知道对于条件概率：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(w_{1},w_{2}...w_{m}) = P(w_{1})*P(w_{2}|w_{1})*P(w_{3}|w_{1}w_{2})..P(w_{m}|w_{1}w_{2}..w_{m-1}) = \prod_{i=1}^m P(w_{i}|w_{1}..w_{i-1}) \approx \prod_{i=1}^m P(w_{i}|w_{i-(n-1)}..w_{i-1})$$  &lt;/div&gt;

&lt;p&gt;    不同于之前讲过的windows classification，在language model中fixed window 可能不是很合理，前5个/10词汇未必一定能很好地引出下一个词汇，因此，我们在这里引入RNN(Recurrent NN)&lt;/p&gt;

&lt;p&gt;    输入是word vectors：&lt;script type=&quot;math/tex&quot;&gt;x_{1}...x_{t-1},x_{t},x_{t+1}...x_{T}&lt;/script&gt;,其中&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;是whole corpus的大小。对于hidden层的一个unit,&lt;script type=&quot;math/tex&quot;&gt;h_{t} = \sigma(w^{hh}h_{t-1} + w^{hx}x_{t})&lt;/script&gt;，输出为&lt;script type=&quot;math/tex&quot;&gt;\hat{y}_{t}=softmax(w^{s}h_{t})&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;w^{hh} \in \mathbb{R}^{D_{h} \times D_{h}}&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;D_{h}&lt;/script&gt;为hidden layer的数据维度。&lt;script type=&quot;math/tex&quot;&gt;w^{hx} \in \mathbb{R}^{D_{h} \times d}&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;为word vector的维度，&lt;script type=&quot;math/tex&quot;&gt;w^{s} \in \mathbb{R}^{V \times D_{h}}&lt;/script&gt;。因此得到&lt;script type=&quot;math/tex&quot;&gt;\hat{y} \in \mathbb{R}^{V}&lt;/script&gt;,是word vocabulary的概率分布。每个predicting word都对应完成的word vocabulary distribution。因此我们定义目标函数为cross entropy loss:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt; $$J(\theta) = -\frac{1}{T} \sum_{t=1}^T \sum_{j=1}^V y_{t,j} \ log_{2} \ \hat{y}_{t,j}$$ &lt;/div&gt;

&lt;p&gt;    最后&lt;script type=&quot;math/tex&quot;&gt;minimal w 2^{J}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;    这里需要指出rnn的问题，我们知道由于input层(hidden层的time step)比较长(这个长度由corpus的sentence长度决定，可以是5也可以是50,也可以是一本书几万个word)，这就回导致gradient vanishing 和gradient explosion。下面推导gradient vanishing的原因。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt1.png&quot; height=&quot;200&quot; weight=&quot;500&quot; /&gt; &lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 
$$\frac{\Delta E_{3}}{\Delta w} =\sum_{i=1}^{3} \frac{\Delta E_{3}}{\Delta \hat{y}_{3}} \frac{\Delta \hat{y}_{3}}{\Delta s_{3}}  \frac{\Delta s_{3}}{\Delta s_{i}}  \frac{\Delta s_{i}}{\Delta w}$$
&lt;/div&gt;
&lt;p&gt;    之前提到的简单Feedforward NN中没有weights sharing，在RNN中由于time step间的&lt;script type=&quot;math/tex&quot;&gt;w_{hh}&lt;/script&gt;是一样的，所以在上式中，我们对所有time step关于&lt;script type=&quot;math/tex&quot;&gt;w_{hh}&lt;/script&gt;的梯度取和。其中&lt;script type=&quot;math/tex&quot;&gt;\frac{\Delta s_{3}}{\Delta s_{i}} = \prod_{j=i+1}^{3} \frac{\Delta s_{j}}{\Delta s_{j-1}}&lt;/script&gt;。我们又知道&lt;script type=&quot;math/tex&quot;&gt;s_{j}=f(w s_{j-1}+b)&lt;/script&gt;，故&lt;script type=&quot;math/tex&quot;&gt;\frac{\Delta s_{j}}{\Delta s_{j-1}} = w f^{&#39;}(w s_{j-1}+b)&lt;/script&gt;，易证&lt;script type=&quot;math/tex&quot;&gt;\frac{\Delta s_{3}}{\Delta s_{i}}&lt;/script&gt;将会是非常大，或是非常小的数(Bengio et al 1994)。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;Deep learning public library:TensorFlow&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    分类：1)通过configuration file文件完成模型：Caffe，DistBelief，CNTK；2）programmatic generation：Torch（Lua），Theano（Python），Tensorflow（Python）。如我们之前Blog提到的，Theano和Tensorflow是非常相似的，这里选择介绍Tensorflow，其一方面有google的背书，另一方面对分布式计算支持较好（一般模型需要在16核GPU上训练1周之久）。&lt;/p&gt;

&lt;p&gt;    1. Tensors，用于表示数据，可以看做是n维数组，可以理解为numpy最基础的功能，而TF则在numpy的基础上提供了tensor funciton, 梯度计算，GPU support这些额外的功能。首先介绍了numpy和tensorflow的相似之处，包括metrics的定义，求和以及broadcast性质。然后指出了两者的不同，在numpy中定义metric时，已经在内存中malloc了相应的参数，而在tf中，仅仅是定义了computation graph，直至evaluated(.eval())时才真正create numerical value。&lt;/p&gt;

&lt;p&gt;    2. Session, 是所有operation的环境，sess.run(y)返回fetch（从global computation graph 从返回的结果），一般将要参与运算的所有tensor定义在同一个session下。tf.InteractiveSession()是在ipython中使用的default session.&lt;/p&gt;

&lt;p&gt;    3. Computation Graph, every function(&lt;script type=&quot;math/tex&quot;&gt;\times \ and \ other \ operation&lt;/script&gt;),就是在computation graph上加入新内容。Computation Graph会record这些操作。 &lt;/p&gt;

&lt;p&gt;    4. Variables,是boxs that hold states. 与constant tensor的区别是，variable在使用(session.run(v)前必须initialize(tf.initialize_all_variables())。variable为什么需要name：通过name来在computation graph 中进行索引。variable的scope(namespace)问题：，背景：复杂的神经网络模型中可能会有数百个variable，我们需要了解namespace。对于Recurrent NN中的weights sharing，我们使用reuse_varaiables()&lt;/p&gt;

&lt;p&gt;    5. Inputting data，定义数据。1）方法一是通过numpy定义metric a，使用tf.convert_to_tensor(a)完成；2）tf.placeholder，dummy nodes （相比于numpy的方法，更符合computation graph的定义）that provide entry points for data to computational graph.通过feed_dict完成从placeholder到numerial data 到映射。&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Stanford &lt;a href=&quot;http://cs224d.stanford.edu/index.html&quot;&gt;cs224d&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Mon, 06 Jun 2016 18:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/06/06/nlp/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/06/06/nlp/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Recommender System</title>
        <description>&lt;p&gt;    近些年来，提到推荐系统，我们更多的是指个性化推荐系统，而个性化推荐系统是较大众化推荐而言的。 &lt;br /&gt;
    大众化推荐经常被用于检索推荐，比如在京东网购时，按照商品“综合排序”展示检索结果，就属于大众化推荐，当然大众化推荐也经常与个性化推荐搭配使用。本文将对个性化推荐展开介绍，大众化推荐不属于本文范畴。 &lt;br /&gt;
    本文根据推荐方法的思想不同，主要介绍了基于人口统计学的推荐等方法。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;1.基于人口统计学的推荐&lt;/h3&gt;
&lt;p&gt;    基于人口统计学的方法(Demographic-Based Recommendation)的思想源自“相似的用户有着相似的爱好”。该方法通过计算系统中用户的相似度，相似度的依据主要是指性别、年龄、工作等，而不包括对商品的评分、购买记录（该方法特指基于用户的协同过滤方法），对a用户推荐与他相似的b用户喜欢的商品。 &lt;br /&gt;
    该方法的特点是，推荐思想简单明了，主要的计算来自对用户相似度的计算，且用户的相似度计算方法十分简单，常用的方法包括欧式距离、余弦相似度等。应用场景十分广泛，京东在其“用户画像”技术中，常用的推荐方法就是该方法，除此之外，该方法用多的应用是与其他的推荐方法相结合。  &lt;br /&gt;
    用户&lt;script type=&quot;math/tex&quot;&gt;X_{1}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;X_{2}&lt;/script&gt;的欧式距离的计算示例如下:   &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$S(X_{1},X_{2}) = \sum_{i=1}^N (x_{1i}-x_{2i})^2 $$&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.基于内容的推荐&lt;/h3&gt;
&lt;p&gt;    和上一个方法十分相似，只不过是假设产生了变化，基于内容的推荐(Content-Based Recommendation)是假设“用户喜欢他之前喜欢的东西“。比如我玩过魔兽，炉石，系统就会为给推荐新出的游戏“守望先锋”。 &lt;br /&gt;
    基于内容的推荐的计算过程大致可以划分为两类，一类是直接计算商品间的相似性，按照相似性由高到低排序进行推荐；另一类是通过构建用户画像，将用户浏览过、购买过的商品的属性作为用户的画像，这个画像描述了用户对于商品属性的偏好特征，然后计算待推荐商品与用户画像之间的相似度，进行推荐。 &lt;br /&gt;
    基于内容的推荐方法有一个优点就是能很好的解决冷启动(Cold－Start)的问题。冷启动是指新产品的推出时如何进行推荐的问题，之前的一些方法的推荐往往是通过该商品的历史评分、历史购买记录进行的，基于内容的推荐则解决该问题。继续拿“守望先锋”来举例，我可以通过TF-IDF来提取该游戏商品介绍文本中的关键词，提取到“暴雪”等字段，根据该“属性”就可以推荐给暴雪系游戏的玩家。 &lt;br /&gt;
    同时需要注意的是，由于要计算商品之间的相似性，所以主要需要需要维护商品到商品属性的矩阵，比如对于一款游戏商品，其商品属性包括游戏类型、出品商等属性字段，因此对于不同类别的的商品需要设计不同的商品属性字段。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;3.基于协同过滤的推荐&lt;/h3&gt;
&lt;p&gt;    首相我想要介绍一下，什么是协同过滤，维基上给出的解释是: &lt;strong&gt;&lt;em&gt;collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration among multiple agents, viewpoints, data sources, etc&lt;/em&gt;&lt;/strong&gt;. &lt;br /&gt;
    这里有一组关键词，collaboration among multiple agents，借助群体的信息，通过别人的对商品的浏览、购买、评价记录来完成对某一个体的推荐，这就是协同过滤的特点。 &lt;br /&gt;
    基于协同过滤的推荐(Collaborative Filtering-Based Recommendation)，又可以细分为基于用户的(User-based),基于物品的(Item-based)以及基于模型的(Model-based)。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;3.1 基于用户的协同过滤&lt;/h4&gt;
&lt;p&gt;    &lt;strong&gt;基于用户的协同过滤&lt;/strong&gt;，与上文中提到的基于人口统计的推荐不同之处的计算用户相似时用的是用户对于商品的评分或者购买浏览记录，而不是人口统计特征。基于用户的协同过滤维护这样一个&lt;script type=&quot;math/tex&quot;&gt;m × k&lt;/script&gt;的矩阵&lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt;.其中有&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt;个用户和&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;个商品,通过计算行与行间的  &lt;/p&gt;

&lt;div id=&quot;content&quot;&gt;

    &lt;table cellspacing=&quot;0&quot;&gt;
    &lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;td&gt;item1&lt;/td&gt;&lt;td&gt;item2&lt;/td&gt;&lt;td&gt;item3&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;user1&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;user2&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;user3&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;/tr&gt;

    &lt;/table&gt;

&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;基于用户的协同过滤&lt;/div&gt;

&lt;h4 id=&quot;section-4&quot;&gt;3.2 基于物品的协同过滤&lt;/h4&gt;

&lt;p&gt;    &lt;strong&gt;基于物品的协同过滤&lt;/strong&gt;，与上文中提到的基于内容的推荐比较相似，不同之处是相似物品的的计算不是通过商品的属性，而是通过网络中用户对商品的历史浏览记录。 &lt;br /&gt;
    如果用户同时浏览过item1和item2，则下表中(1,2)和(2,1)处的值为3，这样可以表征商品之间的关联相似性，这样，一些经常被同时购买的商品会被推荐出来。上述矩阵是通过&lt;script type=&quot;math/tex&quot;&gt;M^{T}M&lt;/script&gt;的到的，&lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt;是基于用户的协同过滤维护的矩阵。&lt;/p&gt;

&lt;div id=&quot;content&quot;&gt;

    &lt;table cellspacing=&quot;0&quot;&gt;
    &lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;td&gt;item1&lt;/td&gt;&lt;td&gt;item2&lt;/td&gt;&lt;td&gt;item3&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;item1&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;item2&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;item3&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;

    &lt;/table&gt;

&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;基于物品的协同过滤&lt;/div&gt;

&lt;h4 id=&quot;section-5&quot;&gt;3.3 基于模型的协同过滤&lt;/h4&gt;

&lt;p&gt;    无论是User-Based还是Item-Based的方法，都需要进行人与人或物与物之间的相似性，这部分的计算量很大，难以实现实时在线响应，而&lt;strong&gt;基于模型的推荐&lt;/strong&gt;(Model-Based)能够很好地解决这个问题，该方法事先根据历史信息“训练”好模型，使用该模型进行推荐。 &lt;br /&gt;
    基于模型的协同过滤方法常见的技术手段包括语义分析(Latent Semantic Analysis),贝叶斯网络(Bayesian Networkds)以及矩阵分解(Matrix Factorization)，下面将以矩阵分解的方法为例，讲解模型的构建和训练。 &lt;br /&gt;
    首先这里要阐述一下矩阵分解的目的，这里，矩阵分解(svd等方法)，并不是为了降维，而是把user-item矩阵分解为user-factor矩阵和item-factor矩阵相乘的形式，下面介绍矩阵分解技术基本流程。 &lt;br /&gt;
&lt;br /&gt;
    1、假设已有稀疏矩阵&lt;script type=&quot;math/tex&quot;&gt;X \in R^{m \times n}&lt;/script&gt;表示用户对商品的打分（浏览、购买记录），该矩阵同“基于用户的协同过滤”中的矩阵，设定&lt;script type=&quot;math/tex&quot;&gt;U \in R^{m \times r}&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;V \in R^{n \times r}&lt;/script&gt;是矩阵&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;的低秩分解。 &lt;br /&gt;
    2、建立优化问题的目标函数：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$argmin [D_{w}(X,f(UV^{T}))+R(U,V)]$$&lt;/div&gt;

&lt;p&gt;    其中，&lt;script type=&quot;math/tex&quot;&gt;D_{w}(X,f(UV^{T}))&lt;/script&gt;是&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;对于&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;的损失函数,&lt;script type=&quot;math/tex&quot;&gt;R(U,V)&lt;/script&gt;是正则化因子(regularizaiton loss),用于避免过度拟合。   &lt;/p&gt;

&lt;p&gt;    3、到这里，已经把问题转换为最优值求解问题，常见的方法包括梯度下降等。&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Zhiyuan Liu &lt;a href=&quot;http://www.amazon.com/s/ref=nb_sb_noss?url=search-alias%3Daps&amp;amp;field-keywords=big+data+intelligence&amp;amp;rh=i%3Aaps%2Ck%3Abig+data+intelligence&quot;&gt;Big Data Intelligence&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 01 May 2016 10:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/05/01/Recommend/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/05/01/Recommend/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Bayes Classification</title>
        <description>&lt;p&gt;    和SVM、神经网络这些分类器一样，贝叶斯分类的基本思想也是通过设定一个“损失函数”，通过最小化损失函数来实现分类结果的最优。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;1.贝叶斯分类中的损失函数是怎么定义的？&lt;/h3&gt;
&lt;p&gt;    首先，定义损失&lt;script type=&quot;math/tex&quot;&gt;\lambda_{ij}&lt;/script&gt;是将本属于&lt;script type=&quot;math/tex&quot;&gt;c_{j}&lt;/script&gt;的样本&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;错误地分为&lt;script type=&quot;math/tex&quot;&gt;c_{i}&lt;/script&gt;带来的损失，且&lt;script type=&quot;math/tex&quot;&gt;\lambda_{jj}=0&lt;/script&gt;,因此对于N类分类问题，一个样本的期望损失为：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$R(c_{i} \mid x) = \sum_{i=1}^N \lambda_{ij}P(c_{i} \mid x)$$&lt;/div&gt;

&lt;p&gt;    假设&lt;script type=&quot;math/tex&quot;&gt;i≠j&lt;/script&gt;，令&lt;script type=&quot;math/tex&quot;&gt;\lambda_{ij}=1&lt;/script&gt;, 如果每个样本&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;的期望损失都能最小化，总体损失必然最小化，&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$arg min R(c_{i} \mid x)$$&lt;/div&gt;

&lt;p&gt;    依照惯例我们进行转换，得出&lt;script type=&quot;math/tex&quot;&gt;R(c_{i} \mid x) = 1 - P(c_{i} \mid x)&lt;/script&gt;,即：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$arg max P(c_{i} \mid x)$$&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.朴素贝叶斯&lt;/h3&gt;
&lt;p&gt;    在我们列出来目标函数后，该谈一谈贝叶斯分类器是如何进行计算的了。&lt;/p&gt;

&lt;p&gt;    首先，给出条件概率、贝叶斯公式的定义：&lt;/p&gt;

&lt;p&gt;    条件概率&lt;script type=&quot;math/tex&quot;&gt;P(A \mid B)&lt;/script&gt;的含义是在B事件发生的基础上发生A事件的概率,即：   &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(A \mid B) = \frac{P(AB)}{P(B)}$$&lt;/div&gt;

&lt;p&gt;    而贝叶斯公式则指出了如何借助&lt;script type=&quot;math/tex&quot;&gt;P(A \mid B)&lt;/script&gt;计算出&lt;script type=&quot;math/tex&quot;&gt;P(AB)&lt;/script&gt;，继而得出&lt;script type=&quot;math/tex&quot;&gt;P(B \mid A)&lt;/script&gt;：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(B \mid A) = \frac{P(A \mid B)P(B)}{P(A)}$$&lt;/div&gt;

&lt;p&gt;    我们在一个N类分类问题中，一个样本&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;,被划分到各类的概率分别为&lt;script type=&quot;math/tex&quot;&gt;P(y_{1} \mid x)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;P(y_{2} \mid x)&lt;/script&gt;…&lt;script type=&quot;math/tex&quot;&gt;P(y_{N} \mid x)&lt;/script&gt;。朴素贝叶斯的分类方法即取条件概率最大的&lt;script type=&quot;math/tex&quot;&gt;y_{i}&lt;/script&gt;作为分类结果。&lt;/p&gt;

&lt;p&gt;    因此我们在进行分类时，将问题转为了如何计算条件概率&lt;script type=&quot;math/tex&quot;&gt;P(y_{i} \mid x)&lt;/script&gt;， 由贝叶斯公式我们知道:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(y_{i} \mid x) = \frac{P(x \mid y_{i})P(y_{i})}{P(x)}$$&lt;/div&gt;

&lt;p&gt;    其中&lt;script type=&quot;math/tex&quot;&gt;P(y_{i})&lt;/script&gt;是“先验概率”，可以由大量的样本数据(训练集)直接给出；而&lt;script type=&quot;math/tex&quot;&gt;P(x)&lt;/script&gt;对于所有的样本个体均相同，作为一个分母，我们可以直接当做一个“缩放因子”不予考虑；  &lt;br /&gt;
    剩下要计算的就是&lt;script type=&quot;math/tex&quot;&gt;P(x \mid y_{i})&lt;/script&gt;，其由&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;的各个属性关于&lt;script type=&quot;math/tex&quot;&gt;y_{i}&lt;/script&gt;的条件概率的联合概率决定，在假设&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;的各个属性&lt;script type=&quot;math/tex&quot;&gt;a_{1}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;a_{2}&lt;/script&gt;…&lt;script type=&quot;math/tex&quot;&gt;a_{m}&lt;/script&gt;相互独立的情况下:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(x \mid y_{i}) =\sum_{i=1}^m P(a_{i} \mid y_{i})$$&lt;/div&gt;

&lt;p&gt;    上式可以直接通过训练集计算得出，以上便是朴素贝叶斯分类器的定义，但根据其定义不难得出朴素贝叶斯存在两处明显不足： &lt;br /&gt;
    &lt;strong&gt;一方面&lt;/strong&gt;一旦属性可选的离散变量较多，样本空间会急遽增大（假设一共有10个属性，每个属性都是二值的，则有&lt;script type=&quot;math/tex&quot;&gt;2^{10}&lt;/script&gt;个样本属性变化范围），需要大量的训练集才能进行有效的分类。一旦某分类下的某一属性值未在样本中出现，即&lt;script type=&quot;math/tex&quot;&gt;P(a_{i} \mid y_{i})=0&lt;/script&gt;，由于我们在计算条件概率时是采用联合概率的乘积形式，于是计算出来的&lt;script type=&quot;math/tex&quot;&gt;P(x \mid y_{i})=0&lt;/script&gt;, 个体属性值的缺少会对抹去其它属性的价值。 &lt;br /&gt;
    &lt;strong&gt;另一方面&lt;/strong&gt;其适用于属性间相互独立的情景。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;3.贝叶斯分类的改进&lt;/h3&gt;

&lt;p&gt;    &lt;strong&gt;针对于第一不足&lt;/strong&gt;，我们可以引入Laplacian Correction，比如对于辨别某犬是否为阿拉斯加犬时，其中一个属性是眼球颜色，该选项共有3个可能，但在训练集中仅出现了其中两种，则对第三种眼球颜色，在计算其&lt;script type=&quot;math/tex&quot;&gt;P(a_{i} \mid y_{i})&lt;/script&gt;时，假定种类&lt;script type=&quot;math/tex&quot;&gt;y_{i}=10&lt;/script&gt;，则按照以往的计算方式有：   &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(a_{i} \mid y_{i})=\frac{0}{10}=0$$&lt;/div&gt;

&lt;p&gt;在经过修正后：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$P(a_{i} \mid y_{i})=\frac{0+1}{10+3}=\frac{1}{13}$$&lt;/div&gt;

&lt;p&gt;其中分子中的1为固定值，分母中的3对应三种可选眼球颜色。 &lt;br /&gt;
    初此之外，将通过对联合概率取对数将“连乘”转换为“连加”的方式也能解决未出现属性值带来的“致命影响”（也能一定程度上解决浮点数下溢问题）。     &lt;br /&gt;
    以上方法虽然能够一定程度上解决第一处不足，但样本属性空间的增加对样本数据的大量需求仍存在。&lt;/p&gt;

&lt;p&gt;    &lt;strong&gt;针对于第二处不足&lt;/strong&gt;，又提出了“半朴素贝叶斯”和“贝叶斯网络”。&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Zhihua Zhou &lt;a href=&quot;https://www.amazon.cn/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%91%A8%E5%BF%97%E5%8D%8E/dp/B01ARKEV1G/ref=sr_1_1?ie=UTF8&amp;amp;qid=1461769135&amp;amp;sr=8-1&amp;amp;keywords=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&quot;&gt;Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Wed, 27 Apr 2016 18:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/04/27/Bayesian/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/04/27/Bayesian/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>神经网络定义及实现</title>
        <description>&lt;p&gt;    随着GPU等硬件的引入以及其在分布式计算的应用(CUDA)，深度学习越来越得到人们的关注，但是“深度”的增加带来的问题，不是仅仅通过计算资源的提高就能解决的，一个主要的问题就是深度的增加会带来梯度弥散，以往的反向传播的训练方式不再那么有效。 &lt;br /&gt;
    在这种情况下，主要有两种方式来训练“深度”网络，一种是进行“权共享(weights sharing)”,比如我们本文介绍的CNN(Convolutional Neural Network)就是这样;另一种解决方式就是使用限制Boltzmann机,进行逐层无监督训练，最后使用反向传播算法进行整个系统的微调。    &lt;br /&gt;
    CNN在图像特征提取发挥着有效作用，RNN(Recurrent Neural Network)则在自然语言领域同样展现了显著的有效性。在这篇文章中，将介绍并训练一个CNN模型，之后将介绍RNN和LSTM.&lt;/p&gt;

&lt;h3 id=&quot;convolutional-neural-network&quot;&gt;1.Convolutional Neural Network&lt;/h3&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/Conv2-9x5-Conv2Conv2.png&quot; width=&quot;500&quot; height=&quot;310&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;    从仿生学的角度思考，我们获取图像时，是由一系列的神经元网络状连接而成，从串联的角度是由一系列由低级神经元（获取图像基本的像素信息）到高级神经元（抽象能力逐步增强），从并联的角度，在低级神经元层，横向来看又有无数低级神经元连接而成，这些神经元负责不同的图像采集区域。由这些低级神经元和高级神经元共同组成cnn的conv layer。而从“视网膜”，到“中枢组织”再到“大脑的视觉皮层（又分为初级高级）”相当于由若干的conv layer，这样就组成了信息逐层处理的cnn。&lt;/p&gt;

&lt;h3 id=&quot;recurrent-neural-network&quot;&gt;2.Recurrent Neural Network&lt;/h3&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/RNN-unrolled.png&quot; width=&quot;470&quot; height=&quot;130&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;    无论是卷积神经网络(cnn)还是全连接神经网络(fully connected network), forward过程中，隐层中每一层的输入都是仅来自上一层，信息是逐层传递的，但我们体验文本阅读时，上下文的关联相比与图像识别的需求更高了。我们理解一个词的含义时，不仅不要这个词本身(一个词本身也是具有许多种含义的)，同时需要来自上下文的支持，因此修正之前神经网络模型的仅从上一层获取输入，增加本层间信息流的输入，就产生了循环神经网络(recurrent nn, 后文中rnn特指recurrent nn, 而非recursive nn),接下来我将介绍一种特殊的RNN：LSTM.&lt;/p&gt;

&lt;h3 id=&quot;long-short-term-memory&quot;&gt;3.Long Short Term Memory&lt;/h3&gt;
&lt;p&gt;    一方面，较长的语句中，前后句间的word间隔过远，信息保留较少，比如：“云在‘天空’中”，‘天空’这个词很容易通过‘云’这个词来锁定，RNN对该情形也能较好地覆盖；但“我生活在法国，所以说一口流利的’法语‘”中，法语与法国间隔较远，存在明显的gap，如果关联词间的gap较大，RNN已经不能有效地关联相关信息.所以RNN只能较好地处理“short term”的情形。 &lt;br /&gt;
    另一方面,由于RNN自身结构的原因(大量的weights),较小的weights经常造成梯度弥散现象(gradient vanishing),梯度弥散现象进一步加剧了‘long term memory’的难度，较大的weights则会造成gradient exploding。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/LSTM3-chain.png&quot; width=&quot;600&quot; height=&quot;240&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;    这里于是引入LSTM的概念，首先，从层内的横向角度来看，区别于RNN中横向传来的一个&lt;script type=&quot;math/tex&quot;&gt;h_{t-1}&lt;/script&gt;，这里增加一个横向传递的变量cell state: &lt;script type=&quot;math/tex&quot;&gt;C_{t-1}&lt;/script&gt;，用以“线性”地保留上文信息(在传统RNN中&lt;script type=&quot;math/tex&quot;&gt;wh_{t-1}*h_{t-1}＋ wx_{t}*x_{t}&lt;/script&gt;经过一个激活函数的非线性变换为&lt;script type=&quot;math/tex&quot;&gt;h_{t}&lt;/script&gt;)。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/LSTM3-C-line.png&quot; width=&quot;600&quot; height=&quot;180&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;    接下来是gates的概念，通过设置引入激活函数(sigmoid)来建立“门”，从而决定是否保留该项信息。每一个图中的黄色方块都是一个完整的神经元，包括weight，输入以及激活函数。激活函数(取&lt;script type=&quot;math/tex&quot;&gt;\sigma(wh_{t-1}*h_{t-1}＋ wx_{t}*x_{t})&lt;/script&gt;)的结果为1时，&lt;script type=&quot;math/tex&quot;&gt;C_{t-1}*1&lt;/script&gt;运算的结果即为保留之前的信息。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/LSTM3-gate.png&quot; width=&quot;80&quot; height=&quot;110&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;    下图所示的第一个gate，是用来决定之前的信息是否舍弃的。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/LSTM3-focus-f.png&quot; width=&quot;580&quot; height=&quot;180&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;    接下来我们来决定什么新信息要被加入到&lt;script type=&quot;math/tex&quot;&gt;C_{t}&lt;/script&gt;中，经过&lt;script type=&quot;math/tex&quot;&gt;+&lt;/script&gt;运算&lt;script type=&quot;math/tex&quot;&gt;C_{t-1}&lt;/script&gt;就变成了&lt;script type=&quot;math/tex&quot;&gt;C_{t}&lt;/script&gt; (&lt;script type=&quot;math/tex&quot;&gt;C_{t}=f_{t}*C_{t-1}+i_{t}*\hat{C}{t}&lt;/script&gt;)&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/LSTM3-focus-i.png&quot; width=&quot;580&quot; height=&quot;180&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;    剩下要输出的便是我们传递给下一隐层和同一层下一个LSTM单元的输入&lt;script type=&quot;math/tex&quot;&gt;h_{t}&lt;/script&gt;&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/LSTM3-focus-o.png&quot; width=&quot;580&quot; height=&quot;180&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;implement-of-lstm&quot;&gt;3. Implement of LSTM&lt;/h3&gt;
&lt;p&gt;    这里我们使用与Theano非常相似的Tensorflow来介绍LSTM的核心代码,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.models.rnn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn_cell&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#初始化lstm模型&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn_cell&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BasicLSTMCell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#初始化横向传播的cell state为0向量&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_batch_of_words&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words_in_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# 逐层处理&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_batch_of_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
	&lt;span class=&quot;c&quot;&gt;# 使用output训练语言概率&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;softmax_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;softmax_b&lt;/span&gt;  
	&lt;span class=&quot;n&quot;&gt;probabilities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# 定义反向传播的loss&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probabilities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Christopher Olah &lt;a href=&quot;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;colah’s blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Tensorflow &lt;a href=&quot;https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html&quot;&gt;Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 17 Feb 2016 18:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9A%E4%B9%89%E5%8F%8A%E5%AE%9E%E7%8E%B0/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9A%E4%B9%89%E5%8F%8A%E5%AE%9E%E7%8E%B0/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Theano &amp; Tensorflow</title>
        <description>&lt;p&gt;    市面上的深度学习框架不断发布，包括：ConvNet,Caffe(图像),Torch以及Tensorflow，其中最引入瞩目的莫过于来自Google的Tensorflow，在这篇文章中，将对提供Python API的Tensorflow以及Theano作简要介绍。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;1.背景&lt;/h3&gt;
&lt;p&gt;    Theano最初是被设计成一套符号表达系统，Tensorflow类似于Theano，也属于符号编程框架	（微软开源的CNTK也是如此）。&lt;/p&gt;

&lt;p&gt;    选择合适的层数，每层的神经元数量，激活函数，损失函数，正则化的参数，然后使用validation数据来判定这次训练的效果。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2.简介&lt;/h3&gt;
&lt;p&gt;    下面将以Theano为例，通过官方给出的Tutorial介绍其基本框架:   &lt;/p&gt;

&lt;h4 id=&quot;theano&quot;&gt;2.1 Theano&lt;/h4&gt;

&lt;h4 id=&quot;section-2&quot;&gt;2.1.1 代数基础&lt;/h4&gt;
&lt;p&gt;    在Theano中所有的数据对象都必须是Theano类型(&lt;a href=&quot;http://deeplearning.net/software/theano/extending/graphstructures.html#type&quot;&gt;Theano Type&lt;/a&gt;)的,这里在代数运算中引入&lt;strong&gt;标量(scalar)&lt;/strong&gt;的概念,将每一个标量数据通过theano.tensor定义成与python存储数据类型（int,float,double等）相一致的Theano类型(iscalar,fscalar,dscalar等)，且这种对应是一对一(即Python存在的数据类型，Theano中均有实现)。   &lt;/p&gt;

&lt;p&gt;    除了标量(scalar)之外，Theano中还包含&lt;strong&gt;vector&lt;/strong&gt;,&lt;strong&gt;matrix&lt;/strong&gt;，在定义这两种类型的Theano变量时，使用相应的dvector(vector contains double elements),dmatrix即可。   &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://deeplearning.net/software/theano/library/compile/function.html&quot;&gt;&lt;strong&gt;theano.function&lt;/strong&gt;方法&lt;/a&gt;，第一个参数是函数的输入参数列表，第二个参数是返回值的列表，且当列表元素数目为1时，可以省去[].&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano.tensor&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;In&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dscalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;y&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#using In to set default value: set default value 5 for y, taking place of y by In(y, default=5) &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#shared value, to define a value that can be &lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Shared变量&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iscalar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;inc&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#UPDATES: An expression which indicates updates to the Value after each function call, also means that expressions for new SharedVariable values&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#UPDATES: (iterable over pairs (shared_variable, new_expression). List, tuple or dict.) &lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;这里要提一下，在代数运算系统中的一些tips： &lt;br /&gt;
1. &lt;strong&gt;缺省值&lt;/strong&gt; &lt;br /&gt;
    首先就是给function中的变量定义缺省值,通过使用&lt;code&gt;In(y,default=5)&lt;/code&gt;代替原来的变量&lt;code&gt;y&lt;/code&gt;. &lt;br /&gt;
2. &lt;strong&gt;Shared变量&lt;/strong&gt; &lt;br /&gt;
    当你需要在不同的函数中持续使用某一个变量时，一般会定义一个shared变量，通过function中的updates参数来改变shared变量的值，在Theano中使用updates的主要目的是提高运算速度（在GPU上），Theano对其进行了特别的优化。同时，还可以通过使用function的&lt;code&gt;givens=[(var1,var2)]&lt;/code&gt;参数(var1的值被var2替换)，来使用state而不改变state.value. &lt;br /&gt;
    引入shared变量的原因：在进行大量求导运算时(GPU擅长)，需要把gradients数据从GPU传输到CPU，通过shared变量，可以省去这个步骤(计算(GPU)与更新(CPU)可以放在一起进行)，一般在训练网络的过程中会将weights定义为shared variable(that persist in the graph between calls).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;随机数&lt;/strong&gt;   &lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano.tensor.shared_randomstreams&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomStreams&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srng&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RandomStreams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#where rng means that random number generator&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.70574274&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.80222456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.25976164&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.18285402&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no_default_updates&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;#Not updating rv_n.rng&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.37328447&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.65746672&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.36302373&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.97484625&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nearly_zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    在给随机数设置seed时，一种方法是直接给RandomStreams设置（如上例所示，或srng.seed(234)），另一种方法是对RandomStreams的某一随机分布变量设置seed，比如对rv_u设置seed,需要通过以下的方法,即使用rng.ser_value和rng.get_value()：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rng_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;borrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# Get the rng for rv_u&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rng_val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;89234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                         &lt;span class=&quot;c&quot;&gt;# seeds the generator&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rv_u&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;borrow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# Assign back seeded rng&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    这里要注意到RandomStream仅工作在CPU环境下（MRG31k3p工作在CPU和GPU下，CURAND仅工作在GPU下）。&lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;2.1.2 导数&lt;/h4&gt;
&lt;p&gt;    在Theano中，使用&lt;code&gt;T.grad(y,x)&lt;/code&gt;来计算表达式y（代价函数）关于x（自变量）的导数。 &lt;br /&gt;
    此外可以使用&lt;code&gt;theano.gradient.jacobian()&lt;/code&gt;来计算雅可比矩阵（多元函数的一阶偏导数矩阵），使用&lt;code&gt;theano.gradient.hessian()&lt;/code&gt;来计算海森矩阵（二阶偏导数矩阵）。&lt;/p&gt;

&lt;h4 id=&quot;section-4&quot;&gt;2.1.3 条件&lt;/h4&gt;
&lt;p&gt;    由于Theano是一种类似于函数式编程的语言，在使用中，Python的if语句只在编译时起作用，编译时会将if判断后的结果进行编译，所以这里需要单独引入条件函数IfElse和Switch。 &lt;br /&gt;
    &lt;code&gt;theano.ifelse(cond, ift, iff)&lt;/code&gt;有三个参数，一个boolean类型的表达式和两个返回变量，&lt;code&gt;tensor.switch(cond, ift, iff)&lt;/code&gt;则为一个tensor和两个返回变量。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano.ifelse&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ifelse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scalars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;a&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;b&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;y&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;z_switch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;switch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;z_lazy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ifelse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;f_switch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_switch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;vm&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f_lazyifelse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_lazy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;vm&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;scan&quot;&gt;2.1.4 scan&lt;/h4&gt;
&lt;p&gt;    设计scan的目的是为了实现循环（递归）地影响一个对象，其主要有四个参数，fn为每次迭代要进行的操作，是一个函数；sequences(y,p)为迭代序列（for(i in range(10)) 中的range(10)）,其中y为要迭代的次数(如果sequences=None，要通过n_steps参数来指定迭代次数)；outputs_info描述使用到前几次迭代结果作为lambda的参数，non_sequences是非序列化的输入，通常用来存储固定的指定值。(good for RNNs)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theano&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_tm2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_tm1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_tm2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_tm1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;outputs_info&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;taps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])],&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;non_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;section-5&quot;&gt;2.1.5 稀疏&lt;/h4&gt;
&lt;p&gt;    Theano专门对稀疏矩阵制定了处理策略，稀疏矩阵中，只有非0元素才会被存储。这里，稀疏矩阵的存储格式有两种csc和csr，当矩阵的行比较多时，建议使用csc:基于矩阵列的存储格式；当行数较少时，则应选择csr:基于矩阵列的存储格式，两者的区别仅在于存储数据的位置。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;theano&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csc_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;x&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;float32&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense_from_sparse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#将稀疏矩阵转换为密集矩阵&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csm_properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#使用sparse.csm_properties来返回一个tensor变量的元组，来表示稀疏矩阵的内部特征。&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#data 属性是一个一维的 ndarray ，它包含稀疏矩阵所有的非0元素。&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#indices 和indptr 属性是用来存储稀疏矩阵中数据的位置的。&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#shape 属性，准确的说是和密集矩阵的shape属性一样的。如果从前三个属性上没法推断，那么它可以在稀疏矩阵创建的时候显式指定 。&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;other-key-words&quot;&gt;2.1.6 Other key words:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;theano.tensor.ones_like(x)&lt;/strong&gt; &lt;br /&gt;
Parameters:	x – tensor that has same shape as output &lt;br /&gt;
Returns a tensor filled with 1s that has same shape as x.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;theano.tensor.dot(x,y)&lt;/strong&gt; &lt;br /&gt;
tensor 变量的点乘操作&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;theano.tensor.nnet.softmax(x)&lt;/strong&gt; or &lt;strong&gt;theano.tensor.nnet.sigmoid(x)&lt;/strong&gt; or &lt;strong&gt;theano.tensor.nnet.relu()&lt;/strong&gt;    &lt;br /&gt;
Returns the standard sigmoid nonlinearity applied to x &lt;br /&gt;
Returns the softmax function of x: &lt;br /&gt;
Compute the element-wise rectified linear activation function(激活函数为Rectified Linear Units,Relu易于求导便于反向传播求误差梯度，由于会使一部分神经元输出为0，从而造成网络的稀疏性，减少了参数的相互依存关系).&lt;/p&gt;

&lt;p&gt;此外使用Lasagne、Keras等建立在theano基础上的library可以作为theano的部分或全部替代,此外这些包支持Pretrained model。&lt;/p&gt;

&lt;h4 id=&quot;tensorflow&quot;&gt;2.2 Tensorflow&lt;/h4&gt;
&lt;p&gt;    Tensorflow和theano非常相似，它的一些亮点包括：可视化(TensorBoard),multi-GPU and multi-node training.&lt;/p&gt;

&lt;p&gt;placeholder来代替tensor
Variables来代替shared variables&lt;/p&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;LISA lab &lt;a href=&quot;http://www.deeplearning.net/tutorial/index.html&quot;&gt;Theano 0.7 documentation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;赵孽 &lt;a href=&quot;https://www.zhihu.com/question/35485591&quot;&gt;如何评价 Theano？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;松尾丰 &lt;a href=&quot;http://book.douban.com/subject/26698202/&quot;&gt;人工智能狂潮&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Kenneth Tran &lt;a href=&quot;https://github.com/zer0n/deepframeworks/blob/master/README.Kenneth Tran md?utm_source=tuicool&amp;amp;utm_medium=referral&quot;&gt;Evaluation of Deep Learning Toolkits&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Stanford/vision &lt;a href=&quot;http://vision.stanford.edu/teaching/cs231n/index.html&quot;&gt;CS231n Winter 2016: Convolutional Neural Networks for Visual Recognition&lt;/a&gt;(Lecture 12)&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Tue, 02 Feb 2016 18:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/02/02/Theano&Tensorflow/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/02/02/Theano&Tensorflow/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Effective Python</title>
        <description>&lt;p&gt;How to modify your Python code style, and use it in a more effective way, this post will introduce the pythonic code style to you.&lt;/p&gt;

&lt;h4 id=&quot;language-sugar-and-suggested-code-style&quot;&gt;Language sugar and suggested code style&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;slice&lt;/strong&gt; &lt;br /&gt;
  You may see [::-1] in python, you also may see [begin:end], which is a brief edition of [begin:end:step]. [begin:end] is suggested, and [begin:end:step] often causes unexpected bugs, for example, it will break for Unicode characters&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;str.format()&lt;/strong&gt;  &lt;br /&gt;
  In C++ ect., %s is used to express a string, it works for python, but the suggested way to express string in python is:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;greet&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Hello world&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;language&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Python&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%(greet)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s from &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%(language)&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s.&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;#or&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;{greet} from {language}.&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;greet&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Hello world&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;Python&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;join&lt;/strong&gt;   &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;s&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;str1&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;str2&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#instead of using str1+str2.&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;with&lt;/strong&gt; &lt;br /&gt;
  To close a file immediately, use ‘with’ to operate the file.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt; 	&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;files/tex.txt&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
 		&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;first line&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;zip&lt;/strong&gt;
  The zip() built-in function can be used to iterate over multiple iterators in parallel. And in Python 2, zip returns the full result as a list of tuples.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#[(1,4),(2,5),(3,6)]&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;assert&lt;/strong&gt; &lt;br /&gt;
  use assert expression1,expression2 to capture the constraint defined by the user. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;deepcopy&lt;/strong&gt; &lt;br /&gt;
  Distinguish shallow copy from deep copy and ‘=’&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;c&quot;&gt;#= reference&lt;/span&gt;
	&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;copy&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#shallow copy, one time of coping&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deepcopy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;#deep copy, copy objects iteratively&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;map &amp;amp; filter&lt;/strong&gt; &lt;br /&gt;
  use &lt;code&gt;map( func, seq1[, seq2...] )&lt;/code&gt; to call a function and return a list of the results, which is equal to &lt;code&gt;[f(x) for x in iterable]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;c&quot;&gt;#first situation: map(func,iterable) where func only has one para&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;#second situation: map(func,iterable1,iterable2) where func(para1,para2) and first elem of iteable1 and iterable2 are used as para1 and para2.&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;#if the func is none, map() is equal to zip()&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;#all constraint to: length of return is equal to length of iterable&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;List comprehensions&lt;/strong&gt; &lt;br /&gt;
  When programming, frequently we want to transform one type of data into another. With the help of list comprehensions we can do it more effectively.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;even_squares&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nums&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;even_squares&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Prints &quot;[0, 4, 16]&quot;&lt;/span&gt;

	&lt;span class=&quot;c&quot;&gt;# filter&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Concurrency &amp;amp; Parallelism&lt;/strong&gt; &lt;br /&gt;
  To make full use of the CPU resource of computer. Concurrent(Thread) program may run thousands of separate paths of execution simultaneously. In contrast, the time parallelism(Process) takes to do the total work is cut in half. &lt;br /&gt;
  In python, The existence of GIL(Global Interpreter Lock) means your program could utilize only one thread at the same time. &lt;br /&gt;
  &lt;strong&gt;I/O-bound&lt;/strong&gt;:Use &lt;code&gt;Threading&lt;/code&gt;(false parallelism) for blocking I/O, which may take more time to execute the CPU-bound program. Also use &lt;code&gt;Lock&lt;/code&gt; class in the &lt;code&gt;Threading&lt;/code&gt; to avoid data races which may not be avoid by GIL.
  &lt;strong&gt;CPU-bound&lt;/strong&gt;:Use &lt;code&gt;Multiprocessing&lt;/code&gt;   &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;*args and **kwargs&lt;/strong&gt; &lt;br /&gt;
  In &lt;code&gt;def(arg, *args, **kwargs)&lt;/code&gt;, &lt;code&gt;*args&lt;/code&gt; means all the default value of arguments, and &lt;code&gt;**kwargs&lt;/code&gt; means all the default key-value arguments. Inside of a function, we use args and kwargs(without *) to call the value passed to this function.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;docstring&lt;/strong&gt; &lt;br /&gt;
  Use docstring(Triple double-quoted strings) to describe your function and class. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
	    :param f:first argument
	    :param arg: another argument
	    :return:{item_key(header of excel/csv):item_value}
    	    &quot;&quot;&quot;&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Generators&lt;/strong&gt; &lt;br /&gt;
  Generator is a kind of Iterator(which has next or __next__ def), However, during the iteration, the result of return will be created when they are called instead of storing them all in memory.   &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generator_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# fist way to call&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generator_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
	&lt;span class=&quot;nb&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# for iterable such as str, use iter() instead of next() for itertor&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# second way to call&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generator_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;
	&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Brett Slatkin &lt;em&gt;Effective Python&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Y.Zhang, Yh.Lai &lt;em&gt;Writing Solid Python Code&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Fri, 15 Jan 2016 18:00:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2016/01/15/Effective/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2016/01/15/Effective/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Support Vector Machine</title>
        <description>&lt;p&gt;Support Vector Machine(&lt;em&gt;SVM&lt;/em&gt;), k-Nearest Neighbors algorithm(&lt;em&gt;k-NN&lt;/em&gt;), and Naive Bayes classifier(&lt;em&gt;NB&lt;/em&gt;) are the most popular and basic approaches for classification. In this article, I will give some mathmetical equations of &lt;em&gt;SVM&lt;/em&gt; and approaches to use &lt;em&gt;SVM&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-is-svm&quot;&gt;1. What is &lt;em&gt;SVM&lt;/em&gt;?&lt;/h3&gt;
&lt;p&gt;In general, there are two kinds of classificaiton, &lt;strong&gt;non-parametric&lt;/strong&gt; and &lt;strong&gt;parametric&lt;/strong&gt; approaches. The parametric approach is to assume a simple parametric model for density functions and to estimate the parameters of the model using an available training set.
However, for most of cases, we can not assume that the desity of data samples can be characterised by a series of parameters in this irregular world. So we introduce the non-parametric method which includes &lt;em&gt;SVM&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;how-it-works&quot;&gt;2. How it works?&lt;/h3&gt;

&lt;h4 id=&quot;maximum-margin-classifier&quot;&gt;2.1 Maximum margin classifier&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;SVM&lt;/em&gt; uses a very simple idea which can be conclude in a word: maximum margin.  &lt;br /&gt;
Suppose that we have a set of training patterns.{&lt;script type=&quot;math/tex&quot;&gt;x_{i},i=1,...,m&lt;/script&gt;} assigned to one of two classes &lt;script type=&quot;math/tex&quot;&gt;\omega_{1}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\omega_{2}&lt;/script&gt;, with corresponding labels &lt;script type=&quot;math/tex&quot;&gt;y_{i}=\pm1&lt;/script&gt;.   &lt;br /&gt;
Denote the linear discriminant function &lt;script type=&quot;math/tex&quot;&gt;g(x)&lt;/script&gt;, where both &lt;script type=&quot;math/tex&quot;&gt;x_{i}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; are n-dimension vectors:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
$$g(x_{i})=w^{T}x_{i}+b$$
&lt;/div&gt;
&lt;p&gt;if &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
g(x)&lt;0 %]]&gt;&lt;/script&gt; we see &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; as label &lt;script type=&quot;math/tex&quot;&gt;y_{i}=-1&lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt;g(x)&gt;0&lt;/script&gt; we see &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; as label &lt;script type=&quot;math/tex&quot;&gt;y_{i}=+1&lt;/script&gt;. Here all points are subject to: &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
$$y_{i}(w^{T}x_{i}+b)\geq0$$
&lt;/div&gt;
&lt;p&gt;The &lt;strong&gt;hyperplane&lt;/strong&gt; is :&lt;script type=&quot;math/tex&quot;&gt;y_{i}(w^{T}x_{i}+b)=0&lt;/script&gt;. &lt;br /&gt;
Then we introduce &lt;strong&gt;functional margin&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; : &lt;script type=&quot;math/tex&quot;&gt;y_{i}(w^{T}x_{i}+b)&lt;/script&gt;, which is a positive number. &lt;br /&gt;
And the &lt;strong&gt;geometric margin&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\tilde{\gamma}&lt;/script&gt;: &lt;script type=&quot;math/tex&quot;&gt;y_{i}(\frac{w^{T}x_{i}}{||w||}+\frac{b}{||w||})&lt;/script&gt;. After introducing the geometric margin, we can scale value of &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; arbitrarily and without changing the geometric margin and the position of this hyperplane: &lt;script type=&quot;math/tex&quot;&gt;y_{i}(w^{T}x_{i}+b)=0&lt;/script&gt;.
For better classify, we should maximize the margin between two groups by some methods about convex optimization which will change the value of &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;.   &lt;/p&gt;

&lt;p&gt;To maximize the geometric margin:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step 1 build the model:&lt;/li&gt;
&lt;/ul&gt;

&lt;div align=&quot;center&quot;&gt;$$\max \limits_{w,b} y_{i}(\frac{w^{T}x_{i}}{||w||}+\frac{b}{||w||})$$&lt;/div&gt;
&lt;p&gt;At first, we constraint that &lt;script type=&quot;math/tex&quot;&gt;||w||=1&lt;/script&gt;, this step can be finished by rescaling the parameters after find solution of &lt;script type=&quot;math/tex&quot;&gt;w^{T}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;. And this constraint can make sure that geometric and the functional margin are the same. However, this contraint is a nonconvex constraint.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step 2 convert to convex optimization problem:&lt;/li&gt;
&lt;/ul&gt;

&lt;div align=&quot;center&quot;&gt;$$\min \limits_{w,b} \frac{1}{2}||w||^{2}$$&lt;/div&gt;
&lt;p&gt;Here another constraint has been added: the functional margin &lt;script type=&quot;math/tex&quot;&gt;\gamma=1&lt;/script&gt; which is the same with: &lt;script type=&quot;math/tex&quot;&gt;\min \limits_{i} y_{i}(w^{T}x_{i}+b)=1 &lt;/script&gt;. And this objective function is a quadratic problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step 3 another kind of convex optimization problem(applied for high or infinite dimensional vector):&lt;/li&gt;
&lt;/ul&gt;

&lt;div align=&quot;center&quot;&gt;$$\frac{1}{2}||w||^{2}-\sum_{i=1}^m\alpha_{i}[y_{i}(w^{T}x_{i}+b)-1]$$&lt;/div&gt;
&lt;p&gt;Using the method of &lt;em&gt;Lagrange multipliers&lt;/em&gt;, you construct a Lagrangian and set the partial derivative with respect to the original parameters &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; and the Lagrange multipliers &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; equal to 0.
The original objective function: &lt;script type=&quot;math/tex&quot;&gt;\min \limits_{w,b} \frac{1}{2}||w||^{2}&lt;/script&gt; , and the constraint function: &lt;script type=&quot;math/tex&quot;&gt;y_{i}(w^{T}x_{i}+b)\geq1&lt;/script&gt;, Then we get the function as showed above. Therefore, to satisfy demand, our objective function turns out:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$\min \limits_{w,b}\max \limits_{\alpha_{i}} \frac{1}{2}||w||^{2}-\sum_{i=1}^m\alpha_{i}[y_{i}(w^{T}x_{i}+b)-1]=L_{P}$$&lt;/div&gt;
&lt;p&gt;which is equal to the objective function in step 2. And the dual form of &lt;script type=&quot;math/tex&quot;&gt;L_{P}&lt;/script&gt; is:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$\max \limits_{\alpha_{i}}\min \limits_{w,b} \frac{1}{2}||w||^{2}-\sum_{i=1}^m\alpha_{i}[y_{i}(w^{T}x_{i}+b)-1]=L_{D}$$&lt;/div&gt;
&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;L_{D}\leq L_{P}&lt;/script&gt; and function &lt;script type=&quot;math/tex&quot;&gt;L_{P}&lt;/script&gt; must be satisfied with the KKT (5 rules). With &lt;script type=&quot;math/tex&quot;&gt;\frac{\delta L_{P}}{\delta w}=0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\frac{\delta L_{P}}{\delta b}=0&lt;/script&gt;, we get:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$w=\sum_{i=1}^m \alpha_{i} y_{i} x_{i}$$&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;$$\sum_{i=1}^m \alpha_{i} y_{i} = 0$$&lt;/div&gt;
&lt;p&gt;Substituting into &lt;script type=&quot;math/tex&quot;&gt;L_{D}&lt;/script&gt;:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$\max \limits_{\alpha_{i}} \sum_{i=1}^m \alpha_{i} - \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_{i} \alpha_{j} y_{i} y_{j} x_{i}^{T} x_{j}$$&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;$$s.t. \alpha_{i}\geq0$$ $$\sum_{i=1}^m \alpha_{i} y_{i} =0$$&lt;/div&gt;
&lt;p&gt;which is also a convex problem, we can get the solution of &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;kernel-trick&quot;&gt;2.2 kernel trick&lt;/h4&gt;
&lt;p&gt;Then, we will introduce the concept of &lt;strong&gt;&lt;em&gt;kernel trick&lt;/em&gt;&lt;/strong&gt;. How can we distinguish ◇ from △ showed below? Obiviously, there are no hyperplane to classify one from the other. &lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;   
&lt;canvas id=&quot;myCanvas&quot; width=&quot;250&quot; height=&quot;180&quot; style=&quot;border:0px solid #c3c3c3;&quot;&gt;
Your browser does not support the canvas element. here is graph written by html.
&lt;/canvas&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var c=document.getElementById(&quot;myCanvas&quot;);
var ctx=c.getContext(&quot;2d&quot;);

var txt1=&quot;△                     ◇&quot;;
var txt2=&quot;◇                     △&quot;;
ctx.font = &quot;20px Helvetica red&quot;;            
ctx.textBaseline = &#39;top&#39;;
ctx.fillText(txt1, 40, 0);
ctx.fillText(txt2, 0,130);
&lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;One possible way for us to solve this problem is to find out a projection function &lt;script type=&quot;math/tex&quot;&gt;\phi(\cdot)&lt;/script&gt; which will figure out a hyperplane in a higher dimension space. However, this method may also bring the dimension disaster problem. To solve this problem, &lt;em&gt;kernel trick&lt;/em&gt; has been created. &lt;br /&gt;
Instead of &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
&lt;\phi(x_{i}),\phi(x)&gt; %]]&gt;&lt;/script&gt;, here we use kernel function:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$K(x_{i},x)$$&lt;/div&gt;
&lt;p&gt;Many kernel functions have been proposed, the most popular menthods are: linear kernel, RBF kernel, polynomial kernel and Sigmoid kernel. &lt;br /&gt;
&lt;strong&gt;Linear kernel&lt;/strong&gt;:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$K(x_{i},x)=x_{i}^{T}x$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;RBF kernel with width &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;&lt;/strong&gt;:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$K(x_{i},x)=exp(\frac{-||x_{i}-x||^{2}}{2 \sigma^{2}})$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;polynomial kernel with degree &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;&lt;/strong&gt;:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$K(x_{i},x)=(x_{i}^{T}x+1)^{d}$$&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Sigmoid kernel with parameter &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;&lt;/strong&gt;:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;$$K(x_{i},x)=tanh(kx_{i}^{T}x+\theta)$$&lt;/div&gt;

&lt;h3 id=&quot;using-svm-in-your-work&quot;&gt;3. Using &lt;em&gt;SVM&lt;/em&gt; in your work.&lt;/h3&gt;
&lt;p&gt;There is a package named &lt;strong&gt;&lt;em&gt;scikit-learn&lt;/em&gt;&lt;/strong&gt; in Python. Find information to install it at &lt;a href=&quot;http://scikit-learn.org/stable/index.html&quot;&gt;here&lt;/a&gt;. We can use the official date sets of &lt;em&gt;scikit-learn&lt;/em&gt;, and examine the performance of classification. Here, we use &lt;em&gt;Iris&lt;/em&gt; dataset. There are 3 kinds of iris, each sample has 4 properties which include petal length, petal width, sepal length, and sepal width.    &lt;/p&gt;

&lt;p&gt;In this experiment, we will show how to conduct a binary classification task. We removed one kind of iris, and two groups of iris are left. After this process, we have two kinds of iris, and each kind has 50 samples. And in order to draw two-dimensional chart, two properties are left: petal length and sepal length.&lt;/p&gt;

&lt;h4 id=&quot;handle-the-dataset&quot;&gt;3.1 Handle the dataset&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;#acquire and handle dataset.&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dateset_property&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dateset_target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#iris.target[num]=2 is corresponding to the third kind of iris&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dateset_property&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dateset_target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dateset_property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dateset_target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;train-the-model&quot;&gt;3.2 Train the model.&lt;/h4&gt;
&lt;p&gt;In this experiment, I apply 4 kinds of kernel function, including &lt;em&gt;linear&lt;/em&gt;,&lt;em&gt;poly&lt;/em&gt;,&lt;em&gt;RBF&lt;/em&gt; and &lt;em&gt;sigmoid&lt;/em&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#split the dataset, and rearrange the list&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# create a mesh to plot in&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meshgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.02&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# title for the plots&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;LinearSVC (linear kernel)&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;SVC with polynomial (degree 3) kernel&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;SVC with RBF kernel&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&#39;SVC with Sigmoid kernel&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf_linear&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;linear&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf_poly&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;poly&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;degree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf_rbf&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf_sigmoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;svm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;sigmoid&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;draw-plot&quot;&gt;3.3 Draw plot&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf_linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf_poly&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf_rbf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf_sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#result are the predict result of all the meshgrid.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;#set the composition of plot&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots_adjust&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wspace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hspace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# Put the result into a color plot.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contourf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;terrain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# Plot the training points&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;terrain&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;u&#39;petal length&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;u&#39;sepal length&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;result-of-classification&quot;&gt;Result of classification&lt;/h4&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;http://qianchaoliu.github.io//assets/screenshot.png&quot; width=&quot;550&quot; height=&quot;440&quot; /&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
Figure: result of classification
&lt;/div&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Andrew R. Webb and Keith D. Copsey &lt;em&gt;Statistical Pattern Recognition(Third Edition)&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Martin Law &lt;a href=&quot;http://www.cise.ufl.edu/class/cis4930sp11dtm/notes/intro_svm_new.pdf&quot;&gt;&lt;em&gt;A Simple Introduction to Support Vector Machines&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Andrew Ng &lt;em&gt;Machine Learning (Stanford CS229)&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 29 Nov 2015 06:35:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2015/11/29/SVM/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2015/11/29/SVM/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Why R?</title>
        <description>&lt;p&gt;As one of the hottest programming languages, R has attracted lots of attention from people who are interested in data analysis. Although python, an advanced and high-level programming language, has satisfied most of needs for data processing, R still has some special advantages. In this short article, I will give a brief intro to R.  &lt;/p&gt;

&lt;h3 id=&quot;the-advantages&quot;&gt;The advantages&lt;/h3&gt;
&lt;p&gt;More professional packages that are ralated with data analytics have been created, there are more than 7000 packages have been created on &lt;a href=&quot;http://cran.r-project.org&quot;&gt;CRAN&lt;/a&gt; by users and programmers around the world.&lt;/p&gt;

&lt;p&gt;Of course, there are some drawbacks of R, such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Little built in support for dynamic or 3-D graphics.&lt;/li&gt;
  &lt;li&gt;Objects must be stored in physical memory, if the objects are too big, you can not load them into memory.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;some-interesting-packages-in-r&quot;&gt;Some interesting packages in R&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ggplot2.org/&quot;&gt;&lt;strong&gt;ggplot2&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt;
python is good at the process of acquiring and handling data, but the ability of data visualization is 
“relatively weak”. In general, we use &lt;strong&gt;matplotlib&lt;/strong&gt; and other libraries to draw figures in Python. The matpoltlib is one of high quality libraies, however, the number of high quality libraries to draw figures are much smaller than that of R. Here in R, one of the most widely known packages to draw beautiful plots is &lt;strong&gt;ggplot2&lt;/strong&gt;.   &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://jliblog.com/app/rweibo&quot;&gt;&lt;strong&gt;Rweibo&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt;
Rweibo is a package based on official API of Sina Weibo. Although there are serious limits of offcial API, such as the maximum quantity of comments allowed for acquiring is 2000 for each Weibo post, the official API can satisfy a smale-scale applicaiton. &lt;br /&gt;
&lt;strong&gt;rMaps&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;can-we-use-r-in-a-more-familiar-way&quot;&gt;Can we use R in a more familiar way?&lt;/h3&gt;
&lt;p&gt;Actually, We can use &lt;strong&gt;rpy2&lt;/strong&gt;, which is an interface to R running embedded in Python. With the help of this interface, we can take advantage of R in the code of Python. &lt;br /&gt;
To install the package of rpy2 (via pip in your terminal): &lt;br /&gt;
 &lt;code&gt;pip install rpy2&lt;/code&gt;   &lt;/p&gt;

&lt;p&gt;Find documentation of rpy2 at &lt;a href=&quot;http://rpy.sourceforge.net/&quot;&gt;rpy.sourceforge.net/&lt;/a&gt; &lt;br /&gt;
In this way, we can complete our daily tasks in codes of Python. &lt;/p&gt;
</description>
        <pubDate>Tue, 10 Nov 2015 06:35:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2015/11/10/R/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2015/11/10/R/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>Brief intro to MongoDB</title>
        <description>&lt;p&gt;    在以前我们使用数据库的时候，讨论的是使用哪一款关系数据库，如今非关系型数据库也渐渐成为一个可替代的选择，这篇文章将简单对非关系型数据库的代表之一MongoDB展开介绍。&lt;/p&gt;

&lt;h4 id=&quot;nosql&quot;&gt;为什么我们需要NoSQL？&lt;/h4&gt;
&lt;p&gt;    虽然像MySQL这数据库已经足够轻量级，但我们在使用存储和使用数据时，有时并不需要使用关系型数据库建立E-R的联系，表与表之间也不需要进行union操作，我们需要的仅仅是一个能让我们对结构化数据进行CRUD (Create, Retrieve, Update, Delete)操作。 &lt;br /&gt;
    此外，NoSQL的火热也与近些年来XML或者JSON等数据结构的流行离不开关系。&lt;/p&gt;

&lt;h4 id=&quot;mongodb&quot;&gt;MongoDB基础&lt;/h4&gt;
&lt;p&gt;    在&lt;a href=&quot;https://docs.mongodb.org/manual/introduction/&quot;&gt;官方文件&lt;/a&gt;中对MongoDB的介绍是“MongoDB is an open-source document database”, 所谓document，对应关系型数据库中的一行数据，且document中的数据是通过键值(key-value)对来组织的, 其对数据的定义类似于JSON或者Python中的dict数据集合, 如下所示，下面的一组数据在MongoDB中被视为表的一行。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;QianchaoLiu&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;20&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;School&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;TJU&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    一些在RDBMS(关系型数据库)中的概念和MongoDB的对应概念如下表&lt;/p&gt;

&lt;div id=&quot;content&quot;&gt;

    &lt;table cellspacing=&quot;0&quot;&gt;
    &lt;tr&gt;&lt;th&gt;RDBMS&lt;/th&gt;&lt;th&gt;MongoDB&lt;/th&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;database&lt;/td&gt;&lt;td&gt;database&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;table&lt;/td&gt;&lt;td&gt;collection&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;column&lt;/td&gt;&lt;td&gt;field&lt;/td&gt;&lt;/tr&gt;

    &lt;/table&gt;

&lt;/div&gt;

&lt;p&gt;    接来下我们将从一些细节上学习MongoDB   &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据类型&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;    MongoDB中包含的数据存储类型包括String,Array,Double,Object,Date,Null等等，详见&lt;a href=&quot;https://docs.mongodb.org/manual/reference/bson-types/&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主键的处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;    每一个表(collection)，都有一个默认的字段(field): “_id”, 系统会默认地对表中的数据建立主键索引。&lt;/p&gt;

&lt;h4 id=&quot;crud&quot;&gt;CRUD操作&lt;/h4&gt;

&lt;p&gt;    下面以Python为例，对MongoDB的操作做出示例。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;连接数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pymongo&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MongoClient&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 连接数据库&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MongoClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;local&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;27017&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 和MongoClient(&#39;mongodb://localhost:27017/&#39;) 效果一样&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 切换到database&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_database&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 和db = connection[&#39;test_database&#39;] 效果一样&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 切换到collection&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;collection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_collection&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    当Colelction和database未提前创建时，这里是滞后创建的，先连接，在创建第一个ducoment后collection和database才会被创建。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Insert document&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;    插入单行数据时，采用下叙述方法：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;QianchaoLiu&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;age&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;20&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;School&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&#39;TJU&#39;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;posts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;posts&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;posts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 插入一行数据&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 或插入数据并返回默认创建的_id:_id = posts.insert_one(post).inserted_id&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    当批量插入数据时，一个方法是使用for循环进行逐条插入，另一种方式是使用	&lt;code&gt;posts.insert_many([{},{}])&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Select&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;posts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_one&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;author&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Mike&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;    在查询唯一一行数据时使用上述方法，当查询多会返回多个数据时，我们使用：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;posts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;author&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Mike&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Thu, 27 Aug 2015 08:35:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2015/08/27/MongoDB/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2015/08/27/MongoDB/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
      <item>
        <title>About pygments</title>
        <description>&lt;p&gt;Highlight for your code by pygments.&lt;/p&gt;

&lt;h3 id=&quot;about-pygments&quot;&gt;1. About pygments&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;pygments&lt;/strong&gt; is a syntax-highlighting package and Python-based code highlighting tool. With it, can highlight our codes in our website.&lt;/p&gt;

&lt;h3 id=&quot;how-to-intall-it&quot;&gt;2. How to intall it:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Step 1, intall &lt;strong&gt;pygments&lt;/strong&gt;:   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;
sudo easy_install pygments.
&lt;/code&gt; &lt;br /&gt;
to make sure that your have installed python and easy_intall in your pc   &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Step 2, get &lt;strong&gt;.css&lt;/strong&gt; file :   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;
pygmentize -f html -S default &amp;gt; pygments.css
&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Step 3, set your jekyll or octopress. Following steps are under the environment of jekyll. &lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;copy this .css file to your local files of jekyll:&lt;code&gt;./css&lt;/code&gt;,   &lt;/li&gt;
      &lt;li&gt;add &lt;code&gt;&amp;lt;link rel=&quot;stylesheet&quot; href=&quot;/css/pygments.css&quot;&amp;gt;&lt;/code&gt; to your &lt;code&gt;head.html&lt;/code&gt;.   &lt;/li&gt;
      &lt;li&gt;and add &lt;code&gt;highlighter: pygments&lt;/code&gt;to your &lt;code&gt;_config.yml&lt;/code&gt;   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;result&quot;&gt;3. Result:&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;foo&#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Fri, 10 Oct 2014 06:35:04 +0800</pubDate>
        <link>http://qianchaoliu.github.io//liuqianchao/update/2014/10/10/about_pygments/</link>
        <guid isPermaLink="true">http://qianchaoliu.github.io//liuqianchao/update/2014/10/10/about_pygments/</guid>
        
        
        <category>liuqianchao</category>
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
