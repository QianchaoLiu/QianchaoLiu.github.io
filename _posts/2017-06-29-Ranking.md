---
layout: post
title:  "Ranking"
date:   2017-06-29 00:00:04
categories: liuqianchao update
---


### 1. Ranking Question

&emsp; 排序，作为信息检索领域的核心问题，这些年来不断以新的形式出现在互联网的方方面面。比如在你在“今日头条”点击了一条刘强东和奶茶妹妹的新闻，在接下来的若干天里，你的信息流首页里，相关的信息将持续排在较高的位置。以上便是排序在协同过滤(Collaborative filtering)领域的应用。   
&emsp;而将机器学习与排序结合到一起，是近20年以来大家常用的做法。机器学习下的排序问题可以概括为：用户给出一个query, 搜索引擎会匹配出一定数目的documents, 然后使用机器学习的模型f(q,d)对documents进行排序。 MSRA的刘铁岩将MLR(Machine-learned Ranking)总结为三类：    

1. Pointwise   
&emsp;认为每一个query-document对都对应一个得分(相关性)，因此该类MLR问题可以看作是回归问题，即训练Regreesion Model，来预测每一个query-ducoument的得分，再将document按照得分由高到低进行排序。   
2. Pairwise   
&emsp;看作是分类问题。    
3. Listwise   
&emsp;上述两种类型都没有考虑每个query下所有document之间的序列关系(只考虑了各个document的预测分). 而listwise考虑的是将一个ranking list作为一个instance进行训练，而非document。

### 2. Evaluation Measure

&emsp;对于MLR模型，其算法结果Evaluation的对象与一般机器学习分类器的有一定的不同，前者更关注相对顺序，而非绝对数值。常用的得Evaluation方法包括：    

- **Normalized Discounted Cumulative Gain(NDCG)**   

&emsp;表示从第一个位置到第n个位置的累积折扣信息增益。每个位置的信息折扣增益为：   

$$
N(n) = Z_n \sum_{j=1}^{n}(2^{r(j)}-1)/log(1+j)
$$

&emsp;(1) 其中$$2^{r(j)}-1$$叫做信息增益(Gain)， $$r(j)$$为排列在第$$j$$个文档的相关度，NDCG将相关度分为$$r$$个等级（比如设为5个等级的话，第1级最差为$$2^1-1=1$$，第5级最好，为$$2^5-1$$）。   
&emsp;(2) $$\frac{1}{log(1+j)}$$表示Positive Discount, j越大，该系数越小(大多数机器算法在未提及$$log$$的底时，默认为$$e$$)。   
&emsp;(3) $$Z_n$$为正则项，加入其的目的是使不同查询之间的DCG可以比较。一般地，取$$Z_n$$为当前检索结果所有文档按相关度由高到底排列是计算出来的DCG。   
&emsp;因此，最大化NDCG来使好的结果排在靠前的位置。    

- **MAP(Mean Average Precision)**    

&emsp;k个query的准确率的平均。每个query准确率的定义为：$$\sum_{j=1}^{n_i} P(j) y_{i,j}$$, 其中$$P(j)$$为Precision, $$y_{i,j}$$为相关性判断：取0和1。



### 3.  Common Models

- **RankNet**

&emsp; 由于上述常用的评价函数不是连续可到的，因此无法通过梯度下降的方法训练分类器的参数。RankNet将目标函数替换机器学习中常用的目标函数：Cross-Entropy：

$$-\hat{P}_{i,j}logP_{i,j} + (1-\hat{P}_{i,j})log(1-P_{i,j})$$

&emsp; 其中$$P_{i,j}$$表示文档$$i$$应该排在文档$$j$$前面的概率，根据实际情况（信息增益等指标）取0， $$\frac{1}{2}$$ 和1。   
&emsp; $$\hat{P}_{i,j}$$是由分类器估计出来的文档$$i,j$$的得分$$s_i, s_j$$后，计算出来的$$i$$应该排在文档$$j$$前面的概率。一般定义：

$$\hat{P}_{i,j}=\frac{1}{1+e^{-\sigma(s_i-s_j)}}$$


- **LambdaRank**

&emsp; 

- **LambdaMart**

