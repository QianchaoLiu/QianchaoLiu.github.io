---
layout: post
title:  "LDA"
date:   2016-10-5 10:00:04
categories: liuqianchao update
---


### 1. What is LDA?   

&emsp; LDA一般被认为是两个概念的缩写，Linear Discriminant Analysis（线性判别分析）和Latent Dirichlet Allocation，本文讨论的内容是后者。   
&emsp; 在了解LDA的原理之前，首先我们要看LDA是用来做什么的：假设我们有多个Document，同时指定要获取的Topic的数目，LDA会告诉我们每个Document归属于某个Topic的概率。根据这功能，我们其实是可以将文本按照topic进行聚类；

### 2. How it works?

&emsp; LDA对于document的形成是有如下的**假设**的：

- 根据Poisson分布，选择这篇document的字数。

- 每篇文章都是包含多个topics的，比如我写这篇blog时，选择的topic可能是LDA占60%，统计方法占20%，代码应用占20%。   
- 接下来对于每个我在document中输入的词，词首先依概率归属于(LDA, 统计方法，代码应用) ，比如60%可能性选择到LDA。   
- 对于我即将输入的这个属于LDA topic的词，它又有一定的概率分布（比如用词a可能性10%，b为15%...）。

&emsp; 接下来，有了以上的假设。当我们使用LDA，来对一些documents进行分析时，假定我们选择了数目为K的topics，我们想要得到每篇document分别属于上述K的topics的概率，以及每个topic下的words分布。**LDA实现的步骤**如下：

- 遍历所有的documents，随机的选择each word in document归属于某个topic，这样我们就得到每篇document的topic distribution和每个topic的words distribution.

- 接下来我们再次进行遍历（遍历每篇document，每篇document的每个word），来改善上述的random的分布。首先定义：

  - $$P(topic \ t  \ \| \ document \ d) = \frac{num \ of \ words \ belong \ to \ topic \ t}{num \ of \ words \ in \ document \ d}$$，document下某topic的概率等于该document下属于该topic的词汇的出现概率

  - $$P(word \ w  \ \| \ topic \ t) = \frac{num \ of \ word \ w}{num \ of \ words \ belong \ to \ topic \ t}$$， 即我们想到的第二个分布,这里是over all documents，属于topic t的word w的数目/所有属于topic t的word的出现总数。     

  用公式来表示$$P(word \ w  \ \| \ document \ d) = P(word \ w  \ \| \ topic \ t)*P(topic \ t  \ \| \ document \ d)$$。这样对于词w，在不同的topic下都可以计算出它的$$P(word \ w  \ \| \ document \ d)$$。这里我们设定一些策略来选择新的topic，可能的策略包括最大化$$P(word \ w  \ \| \ document \ d)$$，实际比较常用的策略为Gibbs Sampling。

- 重复上述，直到达到一个steady state（convergence）。

### 3. Mathematics under the LDA

&emsp; 在理解了实践操作之后，我们尝试做数学分析,

&emsp; **Gamma函数和Gamma分布**：

$$\Gamma(x) = \int_0^\infty t^{x-1}e^{-t} dt$$

&emsp; Gamma函数被设计出来，是因为其具有这样的性质：$$\Gamma(n) = (n-1)!$$

&emsp; 我们稍作变换，可以得出最简单的Gamma分布的密度函数:

$$\int_0^\infty \frac{x^{\alpha - 1}e^{-x}}{\Gamma(\alpha)} dx= 1$$ 

$$Gamma(x \| \alpha) = \frac{x^{\alpha - 1}e^{-x}}{\Gamma(\alpha)} $$

&emsp; 接着，我们做变换令$$x = \beta t$$，则：

$$Gamma(t \| \alpha,\beta) = \frac{\beta^{\alpha}t^{\alpha - 1}e^{-\beta t}}{\Gamma(\alpha)}$$

&emsp; 上式中多出来地一个$$\beta$$,来自$$d\beta x $$

&emsp; 对于Gamma分布，$$\alpha$$称为shape parameter, $$\beta$$称为rate parameter，且$$\alpha$$决定了分布的形状，$$\beta$$决定了分布的坡度。卡方分布和指数分布都是Gamma分布的特殊形式。

&emsp; **Beta分布**：

$$\frac{\Gamma(\alpha + \beta )}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1} (1-x)^{\beta-1}$$

&emsp;Beta分布的产生是与次序统计量关联起来的，IID产生的n个数，按照从小到大的顺序排列，则k-1个比第k的次序统计量小，n-k个比其大，则次序统计量$$X_{(k)} \sim Beta(k-1, n-k)$$


#### Reference
1. Websites [quora](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)
2. rickjin [LDA数学八卦](http://www.52nlp.cn/lda-math-%E6%B1%87%E6%80%BB-lda%E6%95%B0%E5%AD%A6%E5%85%AB%E5%8D%A6)
